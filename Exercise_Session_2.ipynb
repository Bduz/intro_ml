{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0JpCBmt9p3b",
        "outputId": "15a5ed80-60b4-42d8-92fd-bc32115c0d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'intro_pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Bduz/intro_pytorch.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 - Load all the Necessary Modules"
      ],
      "metadata": {
        "id": "CILaN6ZBHr9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/intro_pytorch/')"
      ],
      "metadata": {
        "id": "lWSQO88OHptv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import helperfuncs"
      ],
      "metadata": {
        "id": "DpyuUrVNIBg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Load and Process the Data"
      ],
      "metadata": {
        "id": "V3Dh5nGvGc5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the MNIST data and transform it."
      ],
      "metadata": {
        "id": "5ywgLah5Isnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transformations on the data\n",
        "transform  = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)),])\n",
        "\n",
        "#Load the training data\n",
        "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "#Load the test data\n",
        "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "Kj7CsrEsHdTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - The Model of the Neural Network"
      ],
      "metadata": {
        "id": "eaNxmqZGGtx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the [LeNet](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) model as our ConvNet."
      ],
      "metadata": {
        "id": "F0ScwGoApKfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "    # kernel\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    # an affine operation: y = Wx + b\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      # Max pooling over a (2, 2) window\n",
        "      x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "      # If the size is a square, you can specify with a single number\n",
        "      x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "      x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "model = MnistModel()\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zimiGxvWLeBJ",
        "outputId": "7b12e987-76f2-45d7-aecf-4b50c20fc613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MnistModel(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Train the Model"
      ],
      "metadata": {
        "id": "16Km_6QWHAIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a function for the validation pass\n",
        "def validation(model, testloader, criterion):\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in testloader:\n",
        "\n",
        "        output = model.forward(images)\n",
        "        test_loss += criterion(output, labels).item()\n",
        "\n",
        "        ps = torch.exp(output)\n",
        "        equality = (labels.data == ps.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return test_loss, accuracy"
      ],
      "metadata": {
        "id": "uIs3mn7pd6ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 5\n",
        "print_every = 40\n",
        "steps = 0\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in iter(trainloader):\n",
        "    steps += 1\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model.forward(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if steps % print_every == 0:\n",
        "      # Make sure network is in eval mode for inference\n",
        "      model.eval()\n",
        "      \n",
        "      # Turn off gradients for validation, saves memory and computations\n",
        "      with torch.no_grad():\n",
        "          test_loss, accuracy = validation(model, testloader, criterion)\n",
        "          \n",
        "      print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "            \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "            \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "            \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "      \n",
        "      running_loss = 0\n",
        "      \n",
        "      # Make sure training is back on\n",
        "      model.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0neziT7ER5Fs",
        "outputId": "b14194d4-125e-4603-a780-4454459cd548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10..  Training Loss: 2.214..  Test Loss: 2.193..  Test Accuracy: 0.397\n",
            "Epoch: 1/10..  Training Loss: 2.168..  Test Loss: 2.133..  Test Accuracy: 0.385\n",
            "Epoch: 1/10..  Training Loss: 2.097..  Test Loss: 2.024..  Test Accuracy: 0.391\n",
            "Epoch: 1/10..  Training Loss: 1.926..  Test Loss: 1.814..  Test Accuracy: 0.402\n",
            "Epoch: 1/10..  Training Loss: 1.681..  Test Loss: 1.517..  Test Accuracy: 0.568\n",
            "Epoch: 1/10..  Training Loss: 1.371..  Test Loss: 1.231..  Test Accuracy: 0.665\n",
            "Epoch: 1/10..  Training Loss: 1.114..  Test Loss: 1.008..  Test Accuracy: 0.690\n",
            "Epoch: 1/10..  Training Loss: 0.888..  Test Loss: 0.782..  Test Accuracy: 0.765\n",
            "Epoch: 1/10..  Training Loss: 0.736..  Test Loss: 0.697..  Test Accuracy: 0.780\n",
            "Epoch: 1/10..  Training Loss: 0.637..  Test Loss: 0.608..  Test Accuracy: 0.810\n",
            "Epoch: 1/10..  Training Loss: 0.602..  Test Loss: 0.501..  Test Accuracy: 0.847\n",
            "Epoch: 1/10..  Training Loss: 0.531..  Test Loss: 0.475..  Test Accuracy: 0.854\n",
            "Epoch: 1/10..  Training Loss: 0.502..  Test Loss: 0.425..  Test Accuracy: 0.873\n",
            "Epoch: 1/10..  Training Loss: 0.447..  Test Loss: 0.399..  Test Accuracy: 0.876\n",
            "Epoch: 1/10..  Training Loss: 0.405..  Test Loss: 0.380..  Test Accuracy: 0.887\n",
            "Epoch: 1/10..  Training Loss: 0.411..  Test Loss: 0.395..  Test Accuracy: 0.877\n",
            "Epoch: 1/10..  Training Loss: 0.366..  Test Loss: 0.343..  Test Accuracy: 0.895\n",
            "Epoch: 1/10..  Training Loss: 0.366..  Test Loss: 0.352..  Test Accuracy: 0.893\n",
            "Epoch: 1/10..  Training Loss: 0.343..  Test Loss: 0.315..  Test Accuracy: 0.907\n",
            "Epoch: 1/10..  Training Loss: 0.364..  Test Loss: 0.370..  Test Accuracy: 0.886\n",
            "Epoch: 1/10..  Training Loss: 0.360..  Test Loss: 0.306..  Test Accuracy: 0.908\n",
            "Epoch: 1/10..  Training Loss: 0.312..  Test Loss: 0.278..  Test Accuracy: 0.914\n",
            "Epoch: 1/10..  Training Loss: 0.320..  Test Loss: 0.282..  Test Accuracy: 0.912\n",
            "Epoch: 2/10..  Training Loss: 0.144..  Test Loss: 0.263..  Test Accuracy: 0.917\n",
            "Epoch: 2/10..  Training Loss: 0.278..  Test Loss: 0.251..  Test Accuracy: 0.926\n",
            "Epoch: 2/10..  Training Loss: 0.254..  Test Loss: 0.246..  Test Accuracy: 0.927\n",
            "Epoch: 2/10..  Training Loss: 0.252..  Test Loss: 0.258..  Test Accuracy: 0.920\n",
            "Epoch: 2/10..  Training Loss: 0.275..  Test Loss: 0.233..  Test Accuracy: 0.929\n",
            "Epoch: 2/10..  Training Loss: 0.264..  Test Loss: 0.230..  Test Accuracy: 0.930\n",
            "Epoch: 2/10..  Training Loss: 0.243..  Test Loss: 0.221..  Test Accuracy: 0.933\n",
            "Epoch: 2/10..  Training Loss: 0.247..  Test Loss: 0.225..  Test Accuracy: 0.929\n",
            "Epoch: 2/10..  Training Loss: 0.228..  Test Loss: 0.206..  Test Accuracy: 0.936\n",
            "Epoch: 2/10..  Training Loss: 0.228..  Test Loss: 0.200..  Test Accuracy: 0.940\n",
            "Epoch: 2/10..  Training Loss: 0.231..  Test Loss: 0.202..  Test Accuracy: 0.940\n",
            "Epoch: 2/10..  Training Loss: 0.226..  Test Loss: 0.193..  Test Accuracy: 0.942\n",
            "Epoch: 2/10..  Training Loss: 0.222..  Test Loss: 0.191..  Test Accuracy: 0.944\n",
            "Epoch: 2/10..  Training Loss: 0.206..  Test Loss: 0.200..  Test Accuracy: 0.938\n",
            "Epoch: 2/10..  Training Loss: 0.204..  Test Loss: 0.188..  Test Accuracy: 0.943\n",
            "Epoch: 2/10..  Training Loss: 0.210..  Test Loss: 0.218..  Test Accuracy: 0.932\n",
            "Epoch: 2/10..  Training Loss: 0.213..  Test Loss: 0.173..  Test Accuracy: 0.946\n",
            "Epoch: 2/10..  Training Loss: 0.191..  Test Loss: 0.173..  Test Accuracy: 0.948\n",
            "Epoch: 2/10..  Training Loss: 0.205..  Test Loss: 0.165..  Test Accuracy: 0.950\n",
            "Epoch: 2/10..  Training Loss: 0.176..  Test Loss: 0.164..  Test Accuracy: 0.951\n",
            "Epoch: 2/10..  Training Loss: 0.188..  Test Loss: 0.189..  Test Accuracy: 0.944\n",
            "Epoch: 2/10..  Training Loss: 0.180..  Test Loss: 0.153..  Test Accuracy: 0.954\n",
            "Epoch: 2/10..  Training Loss: 0.162..  Test Loss: 0.156..  Test Accuracy: 0.954\n",
            "Epoch: 3/10..  Training Loss: 0.021..  Test Loss: 0.151..  Test Accuracy: 0.954\n",
            "Epoch: 3/10..  Training Loss: 0.179..  Test Loss: 0.154..  Test Accuracy: 0.953\n",
            "Epoch: 3/10..  Training Loss: 0.153..  Test Loss: 0.156..  Test Accuracy: 0.953\n",
            "Epoch: 3/10..  Training Loss: 0.161..  Test Loss: 0.146..  Test Accuracy: 0.955\n",
            "Epoch: 3/10..  Training Loss: 0.183..  Test Loss: 0.161..  Test Accuracy: 0.947\n",
            "Epoch: 3/10..  Training Loss: 0.164..  Test Loss: 0.142..  Test Accuracy: 0.956\n",
            "Epoch: 3/10..  Training Loss: 0.168..  Test Loss: 0.177..  Test Accuracy: 0.946\n",
            "Epoch: 3/10..  Training Loss: 0.176..  Test Loss: 0.150..  Test Accuracy: 0.955\n",
            "Epoch: 3/10..  Training Loss: 0.143..  Test Loss: 0.140..  Test Accuracy: 0.956\n",
            "Epoch: 3/10..  Training Loss: 0.171..  Test Loss: 0.139..  Test Accuracy: 0.958\n",
            "Epoch: 3/10..  Training Loss: 0.155..  Test Loss: 0.137..  Test Accuracy: 0.959\n",
            "Epoch: 3/10..  Training Loss: 0.151..  Test Loss: 0.145..  Test Accuracy: 0.955\n",
            "Epoch: 3/10..  Training Loss: 0.144..  Test Loss: 0.134..  Test Accuracy: 0.959\n",
            "Epoch: 3/10..  Training Loss: 0.178..  Test Loss: 0.152..  Test Accuracy: 0.952\n",
            "Epoch: 3/10..  Training Loss: 0.155..  Test Loss: 0.126..  Test Accuracy: 0.963\n",
            "Epoch: 3/10..  Training Loss: 0.130..  Test Loss: 0.131..  Test Accuracy: 0.957\n",
            "Epoch: 3/10..  Training Loss: 0.151..  Test Loss: 0.130..  Test Accuracy: 0.960\n",
            "Epoch: 3/10..  Training Loss: 0.136..  Test Loss: 0.126..  Test Accuracy: 0.961\n",
            "Epoch: 3/10..  Training Loss: 0.156..  Test Loss: 0.136..  Test Accuracy: 0.957\n",
            "Epoch: 3/10..  Training Loss: 0.136..  Test Loss: 0.127..  Test Accuracy: 0.960\n",
            "Epoch: 3/10..  Training Loss: 0.136..  Test Loss: 0.119..  Test Accuracy: 0.963\n",
            "Epoch: 3/10..  Training Loss: 0.117..  Test Loss: 0.121..  Test Accuracy: 0.961\n",
            "Epoch: 3/10..  Training Loss: 0.147..  Test Loss: 0.118..  Test Accuracy: 0.963\n",
            "Epoch: 3/10..  Training Loss: 0.151..  Test Loss: 0.139..  Test Accuracy: 0.959\n",
            "Epoch: 4/10..  Training Loss: 0.074..  Test Loss: 0.119..  Test Accuracy: 0.965\n",
            "Epoch: 4/10..  Training Loss: 0.157..  Test Loss: 0.117..  Test Accuracy: 0.963\n",
            "Epoch: 4/10..  Training Loss: 0.124..  Test Loss: 0.112..  Test Accuracy: 0.964\n",
            "Epoch: 4/10..  Training Loss: 0.131..  Test Loss: 0.110..  Test Accuracy: 0.966\n",
            "Epoch: 4/10..  Training Loss: 0.132..  Test Loss: 0.108..  Test Accuracy: 0.967\n",
            "Epoch: 4/10..  Training Loss: 0.130..  Test Loss: 0.113..  Test Accuracy: 0.963\n",
            "Epoch: 4/10..  Training Loss: 0.124..  Test Loss: 0.107..  Test Accuracy: 0.966\n",
            "Epoch: 4/10..  Training Loss: 0.122..  Test Loss: 0.110..  Test Accuracy: 0.967\n",
            "Epoch: 4/10..  Training Loss: 0.137..  Test Loss: 0.114..  Test Accuracy: 0.963\n",
            "Epoch: 4/10..  Training Loss: 0.127..  Test Loss: 0.107..  Test Accuracy: 0.965\n",
            "Epoch: 4/10..  Training Loss: 0.120..  Test Loss: 0.112..  Test Accuracy: 0.964\n",
            "Epoch: 4/10..  Training Loss: 0.120..  Test Loss: 0.125..  Test Accuracy: 0.959\n",
            "Epoch: 4/10..  Training Loss: 0.115..  Test Loss: 0.113..  Test Accuracy: 0.963\n",
            "Epoch: 4/10..  Training Loss: 0.157..  Test Loss: 0.104..  Test Accuracy: 0.968\n",
            "Epoch: 4/10..  Training Loss: 0.121..  Test Loss: 0.112..  Test Accuracy: 0.964\n",
            "Epoch: 4/10..  Training Loss: 0.130..  Test Loss: 0.104..  Test Accuracy: 0.968\n",
            "Epoch: 4/10..  Training Loss: 0.102..  Test Loss: 0.105..  Test Accuracy: 0.968\n",
            "Epoch: 4/10..  Training Loss: 0.108..  Test Loss: 0.111..  Test Accuracy: 0.965\n",
            "Epoch: 4/10..  Training Loss: 0.141..  Test Loss: 0.112..  Test Accuracy: 0.966\n",
            "Epoch: 4/10..  Training Loss: 0.104..  Test Loss: 0.109..  Test Accuracy: 0.965\n",
            "Epoch: 4/10..  Training Loss: 0.103..  Test Loss: 0.098..  Test Accuracy: 0.969\n",
            "Epoch: 4/10..  Training Loss: 0.106..  Test Loss: 0.102..  Test Accuracy: 0.966\n",
            "Epoch: 4/10..  Training Loss: 0.116..  Test Loss: 0.128..  Test Accuracy: 0.962\n",
            "Epoch: 5/10..  Training Loss: 0.022..  Test Loss: 0.112..  Test Accuracy: 0.964\n",
            "Epoch: 5/10..  Training Loss: 0.114..  Test Loss: 0.104..  Test Accuracy: 0.967\n",
            "Epoch: 5/10..  Training Loss: 0.116..  Test Loss: 0.100..  Test Accuracy: 0.970\n",
            "Epoch: 5/10..  Training Loss: 0.103..  Test Loss: 0.097..  Test Accuracy: 0.971\n",
            "Epoch: 5/10..  Training Loss: 0.109..  Test Loss: 0.101..  Test Accuracy: 0.969\n",
            "Epoch: 5/10..  Training Loss: 0.091..  Test Loss: 0.099..  Test Accuracy: 0.972\n",
            "Epoch: 5/10..  Training Loss: 0.102..  Test Loss: 0.097..  Test Accuracy: 0.969\n",
            "Epoch: 5/10..  Training Loss: 0.097..  Test Loss: 0.095..  Test Accuracy: 0.971\n",
            "Epoch: 5/10..  Training Loss: 0.130..  Test Loss: 0.097..  Test Accuracy: 0.973\n",
            "Epoch: 5/10..  Training Loss: 0.101..  Test Loss: 0.090..  Test Accuracy: 0.974\n",
            "Epoch: 5/10..  Training Loss: 0.096..  Test Loss: 0.109..  Test Accuracy: 0.966\n",
            "Epoch: 5/10..  Training Loss: 0.096..  Test Loss: 0.095..  Test Accuracy: 0.971\n",
            "Epoch: 5/10..  Training Loss: 0.111..  Test Loss: 0.107..  Test Accuracy: 0.967\n",
            "Epoch: 5/10..  Training Loss: 0.104..  Test Loss: 0.086..  Test Accuracy: 0.973\n",
            "Epoch: 5/10..  Training Loss: 0.105..  Test Loss: 0.086..  Test Accuracy: 0.975\n",
            "Epoch: 5/10..  Training Loss: 0.103..  Test Loss: 0.090..  Test Accuracy: 0.972\n",
            "Epoch: 5/10..  Training Loss: 0.087..  Test Loss: 0.093..  Test Accuracy: 0.971\n",
            "Epoch: 5/10..  Training Loss: 0.095..  Test Loss: 0.088..  Test Accuracy: 0.971\n",
            "Epoch: 5/10..  Training Loss: 0.104..  Test Loss: 0.091..  Test Accuracy: 0.970\n",
            "Epoch: 5/10..  Training Loss: 0.109..  Test Loss: 0.096..  Test Accuracy: 0.968\n",
            "Epoch: 5/10..  Training Loss: 0.100..  Test Loss: 0.094..  Test Accuracy: 0.968\n",
            "Epoch: 5/10..  Training Loss: 0.119..  Test Loss: 0.088..  Test Accuracy: 0.974\n",
            "Epoch: 5/10..  Training Loss: 0.106..  Test Loss: 0.089..  Test Accuracy: 0.969\n",
            "Epoch: 5/10..  Training Loss: 0.090..  Test Loss: 0.082..  Test Accuracy: 0.974\n",
            "Epoch: 6/10..  Training Loss: 0.058..  Test Loss: 0.083..  Test Accuracy: 0.974\n",
            "Epoch: 6/10..  Training Loss: 0.092..  Test Loss: 0.100..  Test Accuracy: 0.969\n",
            "Epoch: 6/10..  Training Loss: 0.100..  Test Loss: 0.107..  Test Accuracy: 0.964\n",
            "Epoch: 6/10..  Training Loss: 0.101..  Test Loss: 0.080..  Test Accuracy: 0.976\n",
            "Epoch: 6/10..  Training Loss: 0.084..  Test Loss: 0.086..  Test Accuracy: 0.975\n",
            "Epoch: 6/10..  Training Loss: 0.102..  Test Loss: 0.090..  Test Accuracy: 0.973\n",
            "Epoch: 6/10..  Training Loss: 0.084..  Test Loss: 0.083..  Test Accuracy: 0.975\n",
            "Epoch: 6/10..  Training Loss: 0.091..  Test Loss: 0.079..  Test Accuracy: 0.975\n",
            "Epoch: 6/10..  Training Loss: 0.091..  Test Loss: 0.090..  Test Accuracy: 0.971\n",
            "Epoch: 6/10..  Training Loss: 0.109..  Test Loss: 0.092..  Test Accuracy: 0.971\n",
            "Epoch: 6/10..  Training Loss: 0.088..  Test Loss: 0.087..  Test Accuracy: 0.972\n",
            "Epoch: 6/10..  Training Loss: 0.076..  Test Loss: 0.085..  Test Accuracy: 0.976\n",
            "Epoch: 6/10..  Training Loss: 0.086..  Test Loss: 0.079..  Test Accuracy: 0.975\n",
            "Epoch: 6/10..  Training Loss: 0.093..  Test Loss: 0.087..  Test Accuracy: 0.973\n",
            "Epoch: 6/10..  Training Loss: 0.087..  Test Loss: 0.080..  Test Accuracy: 0.975\n",
            "Epoch: 6/10..  Training Loss: 0.091..  Test Loss: 0.077..  Test Accuracy: 0.974\n",
            "Epoch: 6/10..  Training Loss: 0.092..  Test Loss: 0.088..  Test Accuracy: 0.971\n",
            "Epoch: 6/10..  Training Loss: 0.085..  Test Loss: 0.080..  Test Accuracy: 0.977\n",
            "Epoch: 6/10..  Training Loss: 0.085..  Test Loss: 0.076..  Test Accuracy: 0.976\n",
            "Epoch: 6/10..  Training Loss: 0.099..  Test Loss: 0.077..  Test Accuracy: 0.976\n",
            "Epoch: 6/10..  Training Loss: 0.082..  Test Loss: 0.074..  Test Accuracy: 0.977\n",
            "Epoch: 6/10..  Training Loss: 0.062..  Test Loss: 0.076..  Test Accuracy: 0.977\n",
            "Epoch: 6/10..  Training Loss: 0.094..  Test Loss: 0.075..  Test Accuracy: 0.976\n",
            "Epoch: 7/10..  Training Loss: 0.029..  Test Loss: 0.074..  Test Accuracy: 0.978\n",
            "Epoch: 7/10..  Training Loss: 0.070..  Test Loss: 0.078..  Test Accuracy: 0.976\n",
            "Epoch: 7/10..  Training Loss: 0.087..  Test Loss: 0.076..  Test Accuracy: 0.976\n",
            "Epoch: 7/10..  Training Loss: 0.092..  Test Loss: 0.077..  Test Accuracy: 0.977\n",
            "Epoch: 7/10..  Training Loss: 0.078..  Test Loss: 0.081..  Test Accuracy: 0.972\n",
            "Epoch: 7/10..  Training Loss: 0.085..  Test Loss: 0.078..  Test Accuracy: 0.976\n",
            "Epoch: 7/10..  Training Loss: 0.085..  Test Loss: 0.076..  Test Accuracy: 0.977\n",
            "Epoch: 7/10..  Training Loss: 0.086..  Test Loss: 0.096..  Test Accuracy: 0.969\n",
            "Epoch: 7/10..  Training Loss: 0.090..  Test Loss: 0.072..  Test Accuracy: 0.978\n",
            "Epoch: 7/10..  Training Loss: 0.068..  Test Loss: 0.072..  Test Accuracy: 0.976\n",
            "Epoch: 7/10..  Training Loss: 0.088..  Test Loss: 0.073..  Test Accuracy: 0.979\n",
            "Epoch: 7/10..  Training Loss: 0.081..  Test Loss: 0.074..  Test Accuracy: 0.975\n",
            "Epoch: 7/10..  Training Loss: 0.083..  Test Loss: 0.071..  Test Accuracy: 0.976\n",
            "Epoch: 7/10..  Training Loss: 0.067..  Test Loss: 0.076..  Test Accuracy: 0.976\n",
            "Epoch: 7/10..  Training Loss: 0.104..  Test Loss: 0.069..  Test Accuracy: 0.979\n",
            "Epoch: 7/10..  Training Loss: 0.072..  Test Loss: 0.073..  Test Accuracy: 0.978\n",
            "Epoch: 7/10..  Training Loss: 0.074..  Test Loss: 0.067..  Test Accuracy: 0.979\n",
            "Epoch: 7/10..  Training Loss: 0.073..  Test Loss: 0.071..  Test Accuracy: 0.978\n",
            "Epoch: 7/10..  Training Loss: 0.066..  Test Loss: 0.070..  Test Accuracy: 0.977\n",
            "Epoch: 7/10..  Training Loss: 0.082..  Test Loss: 0.079..  Test Accuracy: 0.974\n",
            "Epoch: 7/10..  Training Loss: 0.072..  Test Loss: 0.072..  Test Accuracy: 0.978\n",
            "Epoch: 7/10..  Training Loss: 0.078..  Test Loss: 0.079..  Test Accuracy: 0.975\n",
            "Epoch: 7/10..  Training Loss: 0.072..  Test Loss: 0.067..  Test Accuracy: 0.979\n",
            "Epoch: 7/10..  Training Loss: 0.071..  Test Loss: 0.075..  Test Accuracy: 0.976\n",
            "Epoch: 8/10..  Training Loss: 0.057..  Test Loss: 0.092..  Test Accuracy: 0.972\n",
            "Epoch: 8/10..  Training Loss: 0.066..  Test Loss: 0.065..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.077..  Test Loss: 0.076..  Test Accuracy: 0.975\n",
            "Epoch: 8/10..  Training Loss: 0.067..  Test Loss: 0.076..  Test Accuracy: 0.978\n",
            "Epoch: 8/10..  Training Loss: 0.079..  Test Loss: 0.071..  Test Accuracy: 0.978\n",
            "Epoch: 8/10..  Training Loss: 0.065..  Test Loss: 0.075..  Test Accuracy: 0.977\n",
            "Epoch: 8/10..  Training Loss: 0.063..  Test Loss: 0.069..  Test Accuracy: 0.977\n",
            "Epoch: 8/10..  Training Loss: 0.075..  Test Loss: 0.065..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.074..  Test Loss: 0.073..  Test Accuracy: 0.976\n",
            "Epoch: 8/10..  Training Loss: 0.068..  Test Loss: 0.064..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.070..  Test Loss: 0.069..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.069..  Test Loss: 0.068..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.081..  Test Loss: 0.067..  Test Accuracy: 0.978\n",
            "Epoch: 8/10..  Training Loss: 0.068..  Test Loss: 0.068..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.054..  Test Loss: 0.075..  Test Accuracy: 0.977\n",
            "Epoch: 8/10..  Training Loss: 0.076..  Test Loss: 0.063..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.070..  Test Loss: 0.063..  Test Accuracy: 0.980\n",
            "Epoch: 8/10..  Training Loss: 0.070..  Test Loss: 0.070..  Test Accuracy: 0.978\n",
            "Epoch: 8/10..  Training Loss: 0.080..  Test Loss: 0.070..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.077..  Test Loss: 0.065..  Test Accuracy: 0.980\n",
            "Epoch: 8/10..  Training Loss: 0.087..  Test Loss: 0.065..  Test Accuracy: 0.979\n",
            "Epoch: 8/10..  Training Loss: 0.076..  Test Loss: 0.062..  Test Accuracy: 0.980\n",
            "Epoch: 8/10..  Training Loss: 0.066..  Test Loss: 0.064..  Test Accuracy: 0.979\n",
            "Epoch: 9/10..  Training Loss: 0.023..  Test Loss: 0.059..  Test Accuracy: 0.981\n",
            "Epoch: 9/10..  Training Loss: 0.071..  Test Loss: 0.062..  Test Accuracy: 0.980\n",
            "Epoch: 9/10..  Training Loss: 0.068..  Test Loss: 0.062..  Test Accuracy: 0.980\n",
            "Epoch: 9/10..  Training Loss: 0.061..  Test Loss: 0.066..  Test Accuracy: 0.981\n",
            "Epoch: 9/10..  Training Loss: 0.068..  Test Loss: 0.062..  Test Accuracy: 0.982\n",
            "Epoch: 9/10..  Training Loss: 0.058..  Test Loss: 0.063..  Test Accuracy: 0.980\n",
            "Epoch: 9/10..  Training Loss: 0.050..  Test Loss: 0.060..  Test Accuracy: 0.979\n",
            "Epoch: 9/10..  Training Loss: 0.056..  Test Loss: 0.059..  Test Accuracy: 0.980\n",
            "Epoch: 9/10..  Training Loss: 0.068..  Test Loss: 0.087..  Test Accuracy: 0.971\n",
            "Epoch: 9/10..  Training Loss: 0.060..  Test Loss: 0.059..  Test Accuracy: 0.981\n",
            "Epoch: 9/10..  Training Loss: 0.076..  Test Loss: 0.070..  Test Accuracy: 0.978\n",
            "Epoch: 9/10..  Training Loss: 0.057..  Test Loss: 0.062..  Test Accuracy: 0.979\n",
            "Epoch: 9/10..  Training Loss: 0.051..  Test Loss: 0.062..  Test Accuracy: 0.980\n",
            "Epoch: 9/10..  Training Loss: 0.055..  Test Loss: 0.062..  Test Accuracy: 0.979\n",
            "Epoch: 9/10..  Training Loss: 0.064..  Test Loss: 0.059..  Test Accuracy: 0.980\n",
            "Epoch: 9/10..  Training Loss: 0.074..  Test Loss: 0.062..  Test Accuracy: 0.979\n",
            "Epoch: 9/10..  Training Loss: 0.064..  Test Loss: 0.060..  Test Accuracy: 0.982\n",
            "Epoch: 9/10..  Training Loss: 0.072..  Test Loss: 0.059..  Test Accuracy: 0.981\n",
            "Epoch: 9/10..  Training Loss: 0.068..  Test Loss: 0.059..  Test Accuracy: 0.981\n",
            "Epoch: 9/10..  Training Loss: 0.080..  Test Loss: 0.058..  Test Accuracy: 0.981\n",
            "Epoch: 9/10..  Training Loss: 0.055..  Test Loss: 0.057..  Test Accuracy: 0.981\n",
            "Epoch: 9/10..  Training Loss: 0.071..  Test Loss: 0.066..  Test Accuracy: 0.978\n",
            "Epoch: 9/10..  Training Loss: 0.056..  Test Loss: 0.063..  Test Accuracy: 0.979\n",
            "Epoch: 9/10..  Training Loss: 0.070..  Test Loss: 0.062..  Test Accuracy: 0.981\n",
            "Epoch: 10/10..  Training Loss: 0.056..  Test Loss: 0.056..  Test Accuracy: 0.981\n",
            "Epoch: 10/10..  Training Loss: 0.060..  Test Loss: 0.055..  Test Accuracy: 0.982\n",
            "Epoch: 10/10..  Training Loss: 0.065..  Test Loss: 0.058..  Test Accuracy: 0.981\n",
            "Epoch: 10/10..  Training Loss: 0.080..  Test Loss: 0.060..  Test Accuracy: 0.981\n",
            "Epoch: 10/10..  Training Loss: 0.058..  Test Loss: 0.067..  Test Accuracy: 0.979\n",
            "Epoch: 10/10..  Training Loss: 0.053..  Test Loss: 0.058..  Test Accuracy: 0.981\n",
            "Epoch: 10/10..  Training Loss: 0.054..  Test Loss: 0.062..  Test Accuracy: 0.980\n",
            "Epoch: 10/10..  Training Loss: 0.060..  Test Loss: 0.054..  Test Accuracy: 0.983\n",
            "Epoch: 10/10..  Training Loss: 0.064..  Test Loss: 0.061..  Test Accuracy: 0.979\n",
            "Epoch: 10/10..  Training Loss: 0.065..  Test Loss: 0.054..  Test Accuracy: 0.982\n",
            "Epoch: 10/10..  Training Loss: 0.054..  Test Loss: 0.052..  Test Accuracy: 0.982\n",
            "Epoch: 10/10..  Training Loss: 0.052..  Test Loss: 0.062..  Test Accuracy: 0.980\n",
            "Epoch: 10/10..  Training Loss: 0.059..  Test Loss: 0.053..  Test Accuracy: 0.982\n",
            "Epoch: 10/10..  Training Loss: 0.057..  Test Loss: 0.054..  Test Accuracy: 0.984\n",
            "Epoch: 10/10..  Training Loss: 0.070..  Test Loss: 0.056..  Test Accuracy: 0.982\n",
            "Epoch: 10/10..  Training Loss: 0.045..  Test Loss: 0.059..  Test Accuracy: 0.981\n",
            "Epoch: 10/10..  Training Loss: 0.055..  Test Loss: 0.056..  Test Accuracy: 0.981\n",
            "Epoch: 10/10..  Training Loss: 0.058..  Test Loss: 0.052..  Test Accuracy: 0.982\n",
            "Epoch: 10/10..  Training Loss: 0.062..  Test Loss: 0.054..  Test Accuracy: 0.982\n",
            "Epoch: 10/10..  Training Loss: 0.051..  Test Loss: 0.051..  Test Accuracy: 0.983\n",
            "Epoch: 10/10..  Training Loss: 0.063..  Test Loss: 0.052..  Test Accuracy: 0.983\n",
            "Epoch: 10/10..  Training Loss: 0.057..  Test Loss: 0.055..  Test Accuracy: 0.983\n",
            "Epoch: 10/10..  Training Loss: 0.058..  Test Loss: 0.062..  Test Accuracy: 0.980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Analyze the Results"
      ],
      "metadata": {
        "id": "BloSpo5WHLku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(testloader))\n",
        "\n",
        "with torch.no_grad():\n",
        "  logits = model.forward(images)\n",
        "\n",
        "ps = F.softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "TNK4vAYnGjGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 20\n",
        "helperfuncs.view_classify(images[index], ps[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "GfIj0rvikoBR",
        "outputId": "1c493f8c-3fa0-4b0c-90e1-43f130e3ae5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}